

services:

  # Django app (your existing service)
  django:
    build: .
    container_name: synergyx_django
    image: willisrunner/5g:v1.0.0  # Add your image here
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    command: bash entrypoint.sh  # Ensure this script exists and is executable
    depends_on:
      - prometheus
      - mlflow
    environment:
      - DEBUG=True  # Add more environment variables if needed
      - DJANGO_SETTINGS_MODULE=backend.settings  # Django settings module

  # MLflow service (newly added)
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.3.0  # Use the MLflow image from DockerHub
    container_name: synergyx_mlflow
    ports:
      - "5000:5000"  # MLflow UI port
    volumes:
      - ./mlruns:/mlflow/mlruns  # Store MLflow logs and artifacts on host
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000  # Ensure the service points to the MLflow container
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri /mlflow/mlruns  # Command to start MLflow server

  # Prometheus service (existing)
  prometheus:
    image: prom/prometheus
    container_name: synergyx_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml  # Custom Prometheus config file

  # Grafana service (existing)
  grafana:
    image: grafana/grafana
    container_name: synergyx_grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana  # Persistent Grafana data

  # Node Exporter (existing)
  node_exporter:
    image: prom/node-exporter
    container_name: synergyx_node_exporter
    ports:
      - "9100:9100"  # Exposing node exporter metrics

volumes:
  grafana_data:  # Persistent Grafana data
  mlruns:  # Persistent MLflow data (logs, experiments)
